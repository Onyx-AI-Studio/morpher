{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2859c66-45fa-437c-84d1-7fffedbe1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from string import Template\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc4cf84-22f6-4351-af81-fafce84311a1",
   "metadata": {},
   "source": [
    "# LLM Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3d185-6d1a-484f-ab96-7209282ccca1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Ollama Zephyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56461c5-4f42-4b5f-809a-b823194d7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_generate(input: str, model = \"zephyr-beta\"):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    \n",
    "    payload = json.dumps({\n",
    "      \"model\": model,\n",
    "      \"prompt\": input,\n",
    "      \"stream\": False\n",
    "    })\n",
    "    headers = {\n",
    "      'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    return json.loads(response.text)['response'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52369b6f-e654-4917-ab70-b17b5eaecf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = Template(\"\"\"<|system|>\n",
    "You are a friendly chatbot who always helpful, harmless and honest.</s>\n",
    "<|user|>\n",
    "$input</s>\n",
    "<|assistant|>\"\"\")\n",
    "\n",
    "prompt = chat_template.substitute(input=\"Hello!\")\n",
    "print(ollama_generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc8082b-e76f-4c60-9253-11c8700bf3eb",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbfd8b36-74d2-4d0f-b3f4-b1a46a8b6afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfe050b2-9ae6-4059-b7ae-5f4fc44b1890",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "def openai_generate(input: str, system_message = \"You are an assistant who is always helpful, harmless and honest.\", model = \"gpt-3.5-turbo\"):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": input}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5439e17c-6c2f-4e93-a2f4-15bd61d0453e",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abfaba41-d094-498b-b2d6-a8d4d1779b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(input: str):\n",
    "    # Use Serper API here\n",
    "    return \"Age of Tom Cruise is 42\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "830abb13-6193-4292-978c-e33cd50dcef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meaning_of_life():\n",
    "    return \"42 is the answer to life, the universe, and everything.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "82e844da-41c3-4e5e-8578-2230adf0c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculator(input: str):\n",
    "    prompt_template = Template(\"\"\"You are a calculator, perform the below Task,\n",
    "\n",
    "Task: ```$task```\n",
    "\n",
    "Return only the output. Do not add any text before or after the output.\"\"\")\n",
    "    prompt = prompt_template.substitute(task=input)\n",
    "    result = openai_generate(prompt)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1ec960-b3e6-4ee6-8b2f-ac5186227f48",
   "metadata": {},
   "source": [
    "# System State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ae8e852f-6c6c-4988-bd94-82ba0a95994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_state = {\n",
    "    \"task\": \"\",\n",
    "    \"tools\": {\n",
    "        \"web_search\": {\n",
    "            \"func\": web_search,\n",
    "            \"description\": \"Useful to get information on an unknown topic by searching it online. Input must be a string.\",\n",
    "            # \"return_direct\": True\n",
    "        },\n",
    "        \"meaning_of_life\": {\n",
    "            \"func\": meaning_of_life,\n",
    "            \"description\": \"Useful to get the meaning of life. No inputs needed for this tool.\",\n",
    "        },\n",
    "        \"calculator\": {\n",
    "            \"func\": calculator,\n",
    "            \"description\": \"Useful to perform basic arithmetic operations. Input must be a string.\",\n",
    "        },\n",
    "    },\n",
    "    \"current_plan\": [],\n",
    "    \"short_term_memory\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee4408-af82-4cf5-b6a8-33d38a50af42",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "928e2c88-9a0c-4578-9762-4da71889b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_tools():\n",
    "    tool_str = \"\"\n",
    "    for idx, tool in system_state['tools'].items():\n",
    "        # print(idx, tool['description'])\n",
    "        tool_str += f\"Name: {idx}\\nDescription: {tool['description']}\\n\\n\"\n",
    "    return tool_str.strip()\n",
    "\n",
    "def get_current_step():\n",
    "    if len(system_state['current_plan']) == 0:\n",
    "        return []\n",
    "    return system_state['current_plan'][0]\n",
    "\n",
    "def get_current_plan():\n",
    "    plan = \"[\\n\"\n",
    "    for s in system_state['current_plan']:\n",
    "        plan += \"    \" + s + \",\\n\"\n",
    "    plan += \"]\"\n",
    "    return plan\n",
    "\n",
    "def set_current_plan(plan: str):\n",
    "    system_state['current_plan'] = ast.literal_eval(plan)\n",
    "    # print(system_state['current_plan'])\n",
    "\n",
    "def pretty_print_current_plan():\n",
    "        print(f\"\"\"Current Plan:\n",
    "```\n",
    "{get_current_plan()}\n",
    "```\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18b5cc3d-e876-4dc4-b3a8-a4533838c831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    Use web_search with \"Tom Cruise age\" to find the age of Tom Cruise,\n",
      "    Use calculator with \"age * 2\" to calculate the double of the age,\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(get_current_plan())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae7d9b5-5be6-4674-92e2-9d309bc5542f",
   "metadata": {},
   "source": [
    "# Re-planner Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35f1450-7ff7-4291-9c85-98682bc96a86",
   "metadata": {},
   "source": [
    "**Basic idea**: Based on Plan-and-execute type agents, but capable of more complex tasks as it is able to think and update the plan as and when needed. This helps it to tackle tasks with longer steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9bb1d7-ff59-480b-85b8-d9ccec0d8039",
   "metadata": {},
   "source": [
    "Prepare a plan based on the task. Loop over the below step to proceed,\n",
    "1. `Think`: Keeping the current step in mind, choose the right tool from the arsenel with right input.\n",
    "2. `Act`: Execute the selected tool with the input from the previous step.\n",
    "3. `Observe`: Based on the output of the action step, extract relevant information and update the current plan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c22ae5-4c71-4e15-9fa3-d61b8bc0f96a",
   "metadata": {},
   "source": [
    "## Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d3d534-b8fb-4d62-b876-b1be5acb5a91",
   "metadata": {},
   "source": [
    "### Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4565dc84-08d6-43ed-88bf-e6a113092e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_plan(objective: str):\n",
    "    planner_template = Template(\"\"\"Your task is to analyze complex tasks and break them down into smaller sub-tasks.\n",
    "\n",
    "Instructions:\n",
    "* Do not say your knowledge is out of date, just return the requested information.\n",
    "* Do not say you are a AI language model.\n",
    "* Do not perform the task just yet, analyze and break down the task and return the sub-tasks.\n",
    "* If a tool is used, sub-task must say something like, 'Use tool_a with X to do Y'.\n",
    "* Use only the tools mentioned below if and when needed.\n",
    "* Return the output in the form of an array, follow the below output format strictly.\n",
    "\n",
    "Tools:\n",
    "```\n",
    "$tools\n",
    "```\n",
    "\n",
    "Output format:\n",
    "```\n",
    "[\n",
    "    'sub-task 1', \n",
    "    'sub-task 2', \n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "Task: $input\n",
    "\n",
    "Return the output in the specified format, do not deviate. Do not add any text before or after the output.\n",
    "    \"\"\")\n",
    "    \n",
    "    prompt = planner_template.substitute(input=objective, tools=get_current_tools())\n",
    "    # print(prompt)\n",
    "    return openai_generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48708e0e-5ec3-4c9c-8a87-4cfcdd823764",
   "metadata": {},
   "source": [
    "### Think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e2f27761-25cf-4250-a567-f64a65d322d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def think():\n",
    "    thought_template = Template(\"\"\"Your task is to extract the tool name and the input to the tool for the current step in the specified format.\n",
    "\n",
    "Instructions:\n",
    "* Do not say your knowledge is out of date, just return the requested information.\n",
    "* Do not say you are a AI language model.\n",
    "* Understand the `Current step` and extract the tool name and the complete input to the tool.\n",
    "* Refer to the list of tools available to get the right tool name.\n",
    "* Follow the below output format strictly.\n",
    "\n",
    "Current step: `$current_step`\n",
    "\n",
    "Tools:\n",
    "```\n",
    "$tools\n",
    "```\n",
    "\n",
    "Output format:\n",
    "```\n",
    "{\n",
    "    'current_step': \"current step that is being analyzed\",\n",
    "    'tool_name': \"name of the tool\",\n",
    "    'tool_input': [\"input 1\", \"input 2\", ...]\n",
    "}\n",
    "```\n",
    "\n",
    "Return the output in the specified format, do not deviate. Do not add any text before or after the output.\n",
    "\"\"\")\n",
    "    \n",
    "    prompt = thought_template.substitute(current_step=get_current_step(), tools=get_current_tools())\n",
    "    # print(prompt)\n",
    "    action_inputs = openai_generate(prompt)\n",
    "    action = ast.literal_eval(action_inputs)\n",
    "    return action['tool_name'], action['tool_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ad4e997c-ed24-4e99-9a51-62a10f557e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    'current_step': 'Use calculator with \"42 * 2\" to calculate the double of the age',\n",
      "    'tool_name': 'calculator',\n",
      "    'tool_input': ['42 * 2']\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(action_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "15f57f54-3517-493a-9d10-017eef7bf160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('calculator', ['42 * 2'])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_action = ast.literal_eval(action_inputs)\n",
    "current_action['tool_name'], current_action['tool_input']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a610a-2bee-4f14-96db-6aab2cb9ebf3",
   "metadata": {},
   "source": [
    "### Act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d0e283af-f92f-465f-804f-63a2668ceb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "def execute_action(tool_name: str, tool_input: str):\n",
    "    return system_state['tools'][tool_name]['func'](tool_input)\n",
    "\n",
    "action_output = execute_action(current_action['tool_name'], current_action['tool_input'])\n",
    "print(action_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a43b12-ab37-4344-a9a5-69a9a9c24e81",
   "metadata": {},
   "source": [
    "### Observe and Re-plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a5552bb4-8ac6-43c8-977f-99f585f65fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_plan(action_output: str):\n",
    "    observation_template = Template(\"\"\"Your task is to observer the `Action Output` for the `Current Step` and update the `Current Plan`. Return the updated plan as output in the specified format.\n",
    "\n",
    "Instructions:\n",
    "* Do not say your knowledge is out of date, just return the requested information.\n",
    "* Do not say you are a AI language model.\n",
    "* Update the plan by removing already executed steps or steps which are not necessary now.\n",
    "* Update any values in the next sub-tasks if they are available.\n",
    "* Return `END_PLAN` as the only sub-task if all the steps are executed.\n",
    "* Follow the below output format strictly.\n",
    "\n",
    "Current Step: `$current_step`\n",
    "\n",
    "Action Output:\n",
    "```\n",
    "$action_output\n",
    "```\n",
    "\n",
    "Current Plan:\n",
    "```\n",
    "$current_plan\n",
    "```\n",
    "\n",
    "Output format:\n",
    "```\n",
    "[\n",
    "    'sub-task 1', \n",
    "    'sub-task 2', \n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "Return the output in the specified format, do not deviate. Do not add any text before or after the output.\n",
    "\"\"\")\n",
    "    \n",
    "    prompt = observation_template.substitute(current_step=get_current_step(), action_output=action_output, current_plan=get_current_plan())\n",
    "    # print(prompt)\n",
    "    refreshed_plan = openai_generate(prompt)\n",
    "    return refreshed_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cec4b0a9-59f7-4a3b-8a11-90cc70b368d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to observer the `Action Output` for the `Current Step` and update the `Current Plan`. Return the updated plan as output in the specified format.\n",
      "\n",
      "Instructions:\n",
      "* Do not say your knowledge is out of date, just return the requested information.\n",
      "* Do not say you are a AI language model.\n",
      "* Update the plan by removing already executed steps or steps which are not necessary now.\n",
      "* Update any values in the next sub-tasks if they are available.\n",
      "* Return `END_PLAN` as the only sub-task if all the steps are executed.\n",
      "* Follow the below output format strictly.\n",
      "\n",
      "Current Step: `[]`\n",
      "\n",
      "Action Output:\n",
      "```\n",
      "84\n",
      "```\n",
      "\n",
      "Current Plan:\n",
      "```\n",
      "[\n",
      "]\n",
      "```\n",
      "\n",
      "Output format:\n",
      "```\n",
      "[\n",
      "    'sub-task 1', \n",
      "    'sub-task 2', \n",
      "    ...\n",
      "]\n",
      "```\n",
      "\n",
      "Return the output in the specified format, do not deviate. Do not add any text before or after the output.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e2f27d45-d0ac-4494-a617-9bc68a0b836a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    'END_PLAN'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(refreshed_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd76ba9-6e68-4c55-bb23-6cf83cd22b33",
   "metadata": {},
   "source": [
    "## Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bd5264dd-3157-4bce-81bc-b814335a8fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Plan:\n",
      "```\n",
      "[\n",
      "    Use web_search with \"Tom Cruise age\" to find the age of Tom Cruise,\n",
      "    Use calculator with \"age * 2\" to calculate the double of the age,\n",
      "]\n",
      "```\n",
      "##### Execution Started #####\n",
      "Executing Step: Use web_search with \"Tom Cruise age\" to find the age of Tom Cruise\n",
      "\n",
      "THINK: Keeping the current step in mind, choose the right tool from the list with the right input\n",
      "Tool: web_search, Tool inputs: ['Tom Cruise age']\n",
      "\n",
      "ACT: Execute the selected tool with the input from the previous step\n",
      "Output of the current action: Age of Tom Cruise is 42\n",
      "\n",
      "OBSERVE: Based on the output of the action step, extract relevant information and refresh the current plan\n",
      "Current Plan:\n",
      "```\n",
      "[\n",
      "    Use calculator with \"42 * 2\" to calculate the double of the age,\n",
      "]\n",
      "```\n",
      "##### Execution Done #####\n",
      "\n",
      "\n",
      "##### Execution Started #####\n",
      "Executing Step: Use calculator with \"42 * 2\" to calculate the double of the age\n",
      "\n",
      "THINK: Keeping the current step in mind, choose the right tool from the list with the right input\n",
      "Tool: calculator, Tool inputs: ['42 * 2']\n",
      "\n",
      "ACT: Execute the selected tool with the input from the previous step\n",
      "Output of the current action: 84\n",
      "\n",
      "OBSERVE: Based on the output of the action step, extract relevant information and refresh the current plan\n",
      "Current Plan:\n",
      "```\n",
      "[\n",
      "    END_PLAN,\n",
      "]\n",
      "```\n",
      "##### Execution Done #####\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "objective = \"Calculate the double of the age of Tom Cruise\"\n",
    "\n",
    "# Initialize system state\n",
    "system_state['task'] = objective\n",
    "set_current_plan(prepare_plan(objective))\n",
    "    \n",
    "pretty_print_current_plan()\n",
    "\n",
    "while \"END_PLAN\" not in str(system_state['current_plan'][0]):\n",
    "    current_step = get_current_step()\n",
    "    print(f\"##### Execution Started #####\")\n",
    "    print(f\"Executing Step: {get_current_step()}\")\n",
    "\n",
    "    # think\n",
    "    print(\"\\nTHINK: Keeping the current step in mind, choose the right tool from the list with the right input\")\n",
    "    tool_name, tool_input = think()\n",
    "    print(f'Tool: {tool_name}, Tool inputs: {tool_input}')\n",
    "\n",
    "    # act\n",
    "    print(\"\\nACT: Execute the selected tool with the input from the previous step\")\n",
    "    action_output = execute_action(tool_name, tool_input)\n",
    "    print(f\"Output of the current action: {action_output}\")\n",
    "\n",
    "    # observe and refresh plan\n",
    "    print(\"\\nOBSERVE: Based on the output of the action step, extract relevant information and refresh the current plan\")\n",
    "    set_current_plan(refresh_plan(action_output))\n",
    "    pretty_print_current_plan()\n",
    "\n",
    "    print(f\"##### Execution Done #####\\n\\n\")\n",
    "\n",
    "# Implement memory to analyze and output the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99068a22-ea7b-42a4-8c81-920ba338d9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c274b-bf88-4cf7-92d4-0cede016c4e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ea0372-9cd0-41ae-bd0d-9f644edd2fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee23190-e1f6-4919-b110-30e11d8ca36c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa4815-0813-4756-837d-ca6bb2e0751a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425171bc-ed3f-4259-8e21-63ad2a782366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172c8c41-56ac-404a-a9b4-a7401fe7fec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3c9655-7ba3-49e6-b740-cfadcd39dcac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db9e1a3-dde6-4b00-89bb-30d8b952f3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3a514-c307-4e1e-a7e9-b82cf1b1bc2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee2ba67-2159-440a-a489-4a988a4cfc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fdf73d-0a8c-4b24-a7ac-59e4685678de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4e74ce-312b-4fcd-9636-e7325db0f1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36408efd-65a0-472e-8f59-06781af93b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1c18b-8067-4611-b3a9-1e1cdc3f7029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dd1de8-05ad-4c91-ae98-be770b073dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea962bad-c86d-43cd-b32b-1444549dcc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddbfcfa-72f2-4aa3-8d3a-3e15adad29e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e35d2cf-e842-475f-954b-90abb82bec66",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc854d-3422-43d4-a5b3-8c6209c0f717",
   "metadata": {},
   "source": [
    "## Zephyr templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4566f956-e8c3-4cf2-94da-ca6e5e197e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_template = Template(\"\"\"<|system|>\n",
    "You are an assistant who is always helpful, harmless and honest.</s>\n",
    "<|user|>\n",
    "Your task is to analyze complex tasks and break them down into smaller sub-tasks.\n",
    "\n",
    "Instructions:\n",
    "* Do not say your knowledge is out of date, just return the requested information.\n",
    "* Do not say you are a AI language model.\n",
    "* Do not perform the task just yet, analyze and break down the task and return the sub-tasks.\n",
    "* If a tool is used, sub-task must say something like, 'Use tool_a with X to do Y'.\n",
    "* Use only the tools mentioned below if and when needed.\n",
    "* The sub-tasks must not say 'store the data'. All the data is by default stored in memory.\n",
    "* Return the output in the form of an array, follow the below output format strictly.\n",
    "\n",
    "Tools:\n",
    "```\n",
    "$tools\n",
    "```\n",
    "\n",
    "Output format:\n",
    "```\n",
    "[\n",
    "    'sub-task 1', \n",
    "    'sub-task 2', \n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "Task: $input\n",
    "\n",
    "Return the output in the specified format, do not deviate. Do not add any text before or after the output.</s>\n",
    "<|assistant|>\"\"\")\n",
    "\n",
    "prompt = planner_template.substitute(input=\"Calculate the double of the age of Tom Cruise\", tools=get_current_tools())\n",
    "# print(prompt)\n",
    "set_current_plan(ollama_generate(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573ae06-8540-4eea-813e-31a7c57bc2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "thought_template = Template(\"\"\"<|system|>\n",
    "You are an assistant who is always helpful, harmless and honest.</s>\n",
    "<|user|>\n",
    "Your task is to extract the tool name and the input to the tool for the current step in the specified format.\n",
    "\n",
    "Instructions:\n",
    "* Do not say your knowledge is out of date, just return the requested information.\n",
    "* Do not say you are a AI language model.\n",
    "* Understand the `Current step` and extract the tool name and the complete input to the tool.\n",
    "* Refer to the list of tools available to get the right tool name.\n",
    "* Follow the below output format strictly.\n",
    "\n",
    "Current step: `$current_step`\n",
    "\n",
    "Tools:\n",
    "```\n",
    "$tools\n",
    "```\n",
    "\n",
    "Output format:\n",
    "```\n",
    "{\n",
    "    'current_step': \"current step that is being analyzed\",\n",
    "    'tool_name': \"name of the tool\",\n",
    "    'tool_input': [\"input 1\", \"input 2\", ...]\n",
    "}\n",
    "```\n",
    "\n",
    "Return the output in the specified format, do not deviate. Do not add any text before or after the output.</s>\n",
    "<|assistant|>\"\"\")\n",
    "\n",
    "prompt = action_template.substitute(current_step=get_current_step(), tools=get_current_tools())\n",
    "# print(prompt)\n",
    "print(ollama_generate(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f176820-fc4f-405f-85fe-2fdcd95741d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
