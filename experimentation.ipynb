{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2859c66-45fa-437c-84d1-7fffedbe1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from string import Template\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc4cf84-22f6-4351-af81-fafce84311a1",
   "metadata": {},
   "source": [
    "# LLM Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3d185-6d1a-484f-ab96-7209282ccca1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Ollama Zephyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56461c5-4f42-4b5f-809a-b823194d7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_generate(input: str, model = \"zephyr-beta\"):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    \n",
    "    payload = json.dumps({\n",
    "      \"model\": model,\n",
    "      \"prompt\": input,\n",
    "      \"stream\": False\n",
    "    })\n",
    "    headers = {\n",
    "      'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    return json.loads(response.text)['response'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52369b6f-e654-4917-ab70-b17b5eaecf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = Template(\"\"\"<|system|>\n",
    "You are a friendly chatbot who always helpful, harmless and honest.</s>\n",
    "<|user|>\n",
    "$input</s>\n",
    "<|assistant|>\"\"\")\n",
    "\n",
    "prompt = chat_template.substitute(input=\"Hello!\")\n",
    "print(ollama_generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc8082b-e76f-4c60-9253-11c8700bf3eb",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbfd8b36-74d2-4d0f-b3f4-b1a46a8b6afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfe050b2-9ae6-4059-b7ae-5f4fc44b1890",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "def openai_generate(input: str, system_message = \"You are an assistant who is always helpful, harmless and honest.\", model = \"gpt-3.5-turbo\"):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": input}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5439e17c-6c2f-4e93-a2f4-15bd61d0453e",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abfaba41-d094-498b-b2d6-a8d4d1779b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(input: str):\n",
    "    # Use Serper API here\n",
    "    return \"Age of Tom Cruise is 42\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "830abb13-6193-4292-978c-e33cd50dcef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meaning_of_life():\n",
    "    return \"42 is the answer to life, the universe, and everything.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82e844da-41c3-4e5e-8578-2230adf0c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculator():\n",
    "    return \"5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1ec960-b3e6-4ee6-8b2f-ac5186227f48",
   "metadata": {},
   "source": [
    "# System State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae8e852f-6c6c-4988-bd94-82ba0a95994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_state = {\n",
    "    \"task\": \"Calculate the double of the age of Tom Cruise\",\n",
    "    \"tools\": {\n",
    "        \"web_search\": {\n",
    "            \"func\": web_search,\n",
    "            \"description\": \"Useful to get information on an unknown topic by searching it online. Input must be a string.\",\n",
    "            # \"return_direct\": True\n",
    "        },\n",
    "        \"meaning_of_life\": {\n",
    "            \"func\": meaning_of_life,\n",
    "            \"description\": \"Useful to get the meaning of life. No inputs needed for this tool.\",\n",
    "        },\n",
    "        \"calculator\": {\n",
    "            \"func\": calculator,\n",
    "            \"description\": \"Useful to perform basic arithmetic operations. Input must be a string.\",\n",
    "        },\n",
    "    },\n",
    "    \"current_plan\": [],\n",
    "    \"short_term_memory\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee4408-af82-4cf5-b6a8-33d38a50af42",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "928e2c88-9a0c-4578-9762-4da71889b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_tools():\n",
    "    tool_str = \"\"\n",
    "    for idx, tool in system_state['tools'].items():\n",
    "        # print(idx, tool['description'])\n",
    "        tool_str += f\"Name: {idx}\\nDescription: {tool['description']}\\n\\n\"\n",
    "    return tool_str.strip()\n",
    "\n",
    "def get_current_step():\n",
    "    return system_state['current_plan'][0]\n",
    "\n",
    "def set_current_plan(plan: str):\n",
    "    system_state['current_plan'] = ast.literal_eval(plan)\n",
    "    print(system_state['current_plan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae7d9b5-5be6-4674-92e2-9d309bc5542f",
   "metadata": {},
   "source": [
    "# Re-planner Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35f1450-7ff7-4291-9c85-98682bc96a86",
   "metadata": {},
   "source": [
    "**Basic idea**: Based on Plan-and-execute type agents, but capable of more complex tasks as it is able to think and update the plan as and when needed. This helps it to tackle tasks with longer steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9bb1d7-ff59-480b-85b8-d9ccec0d8039",
   "metadata": {},
   "source": [
    "Prepare a plan based on the task. Loop over the below step to proceed,\n",
    "1. `Think`: Keeping the current step in mind, choose the right tool from the arsenel with right input.\n",
    "2. `Act`: Execute the selected tool with the input from the previous step.\n",
    "3. `Observe`: Based on the output of the action step, extract relevant information.\n",
    "4. `Update`: Based on the available data till now, re-think and update the plan if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d3d534-b8fb-4d62-b876-b1be5acb5a91",
   "metadata": {},
   "source": [
    "## Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4565dc84-08d6-43ed-88bf-e6a113092e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Use web_search with \"Tom Cruise age\" to find the age of Tom Cruise', 'Use calculator with \"age * 2\" to calculate the double of the age']\n"
     ]
    }
   ],
   "source": [
    "planner_template = Template(\"\"\"Your task is to analyze complex tasks and break them down into smaller sub-tasks.\n",
    "\n",
    "Instructions:\n",
    "* Do not say your knowledge is out of date, just return the requested information.\n",
    "* Do not say you are a AI language model.\n",
    "* Do not perform the task just yet, analyze and break down the task and return the sub-tasks.\n",
    "* If a tool is used, sub-task must say something like, 'Use tool_a with X to do Y'.\n",
    "* Use only the tools mentioned below if and when needed.\n",
    "* Return the output in the form of an array, follow the below output format strictly.\n",
    "\n",
    "Tools:\n",
    "```\n",
    "$tools\n",
    "```\n",
    "\n",
    "Output format:\n",
    "```\n",
    "[\n",
    "    'sub-task 1', \n",
    "    'sub-task 2', \n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "Task: $input\n",
    "\n",
    "Return the output in the specified format, do not deviate. Do not add any text before or after the output.\n",
    "\"\"\")\n",
    "\n",
    "prompt = planner_template.substitute(input=\"Calculate the double of the age of Tom Cruise\", tools=get_current_tools())\n",
    "# print(prompt)\n",
    "set_current_plan(openai_generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48708e0e-5ec3-4c9c-8a87-4cfcdd823764",
   "metadata": {},
   "source": [
    "## Think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2f27761-25cf-4250-a567-f64a65d322d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "thought_template = Template(\"\"\"Your task is to extract the tool name and the input to the tool for the current step in the specified format.\n",
    "\n",
    "Instructions:\n",
    "* Do not say your knowledge is out of date, just return the requested information.\n",
    "* Do not say you are a AI language model.\n",
    "* Understand the `Current step` and extract the tool name and the complete input to the tool.\n",
    "* Refer to the list of tools available to get the right tool name.\n",
    "* Follow the below output format strictly.\n",
    "\n",
    "Current step: `$current_step`\n",
    "\n",
    "Tools:\n",
    "```\n",
    "$tools\n",
    "```\n",
    "\n",
    "Output format:\n",
    "```\n",
    "{\n",
    "    'current_step': \"current step that is being analyzed\",\n",
    "    'tool_name': \"name of the tool\",\n",
    "    'tool_input': [\"input 1\", \"input 2\", ...]\n",
    "}\n",
    "```\n",
    "\n",
    "Return the output in the specified format, do not deviate. Do not add any text before or after the output.\n",
    "\"\"\")\n",
    "\n",
    "prompt = thought_template.substitute(current_step=get_current_step(), tools=get_current_tools())\n",
    "# print(prompt)\n",
    "action_inputs = openai_generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad4e997c-ed24-4e99-9a51-62a10f557e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    'current_step': 'Use web_search with \"Tom Cruise age\" to find the age of Tom Cruise',\n",
      "    'tool_name': 'web_search',\n",
      "    'tool_input': ['Tom Cruise age']\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(action_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15f57f54-3517-493a-9d10-017eef7bf160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('web_search', ['Tom Cruise age'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_action = ast.literal_eval(action_inputs)\n",
    "current_action['tool_name'], current_action['tool_input']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a610a-2bee-4f14-96db-6aab2cb9ebf3",
   "metadata": {},
   "source": [
    "## Act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0e283af-f92f-465f-804f-63a2668ceb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Age of Tom Cruise is 42'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def execute_action(tool_name: str, tool_input: str):\n",
    "    return system_state['tools'][tool_name]['func'](tool_input)\n",
    "\n",
    "execute_action(current_action['tool_name'], current_action['tool_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61278fcf-7615-4426-ab9f-1fa8923c6662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99068a22-ea7b-42a4-8c81-920ba338d9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c274b-bf88-4cf7-92d4-0cede016c4e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ea0372-9cd0-41ae-bd0d-9f644edd2fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee23190-e1f6-4919-b110-30e11d8ca36c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa4815-0813-4756-837d-ca6bb2e0751a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425171bc-ed3f-4259-8e21-63ad2a782366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172c8c41-56ac-404a-a9b4-a7401fe7fec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3c9655-7ba3-49e6-b740-cfadcd39dcac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db9e1a3-dde6-4b00-89bb-30d8b952f3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3a514-c307-4e1e-a7e9-b82cf1b1bc2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee2ba67-2159-440a-a489-4a988a4cfc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fdf73d-0a8c-4b24-a7ac-59e4685678de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4e74ce-312b-4fcd-9636-e7325db0f1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36408efd-65a0-472e-8f59-06781af93b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1c18b-8067-4611-b3a9-1e1cdc3f7029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dd1de8-05ad-4c91-ae98-be770b073dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea962bad-c86d-43cd-b32b-1444549dcc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddbfcfa-72f2-4aa3-8d3a-3e15adad29e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e35d2cf-e842-475f-954b-90abb82bec66",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc854d-3422-43d4-a5b3-8c6209c0f717",
   "metadata": {},
   "source": [
    "## Zephyr templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4566f956-e8c3-4cf2-94da-ca6e5e197e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_template = Template(\"\"\"<|system|>\n",
    "You are an assistant who is always helpful, harmless and honest.</s>\n",
    "<|user|>\n",
    "Your task is to analyze complex tasks and break them down into smaller sub-tasks.\n",
    "\n",
    "Instructions:\n",
    "* Do not say your knowledge is out of date, just return the requested information.\n",
    "* Do not say you are a AI language model.\n",
    "* Do not perform the task just yet, analyze and break down the task and return the sub-tasks.\n",
    "* If a tool is used, sub-task must say something like, 'Use tool_a with X to do Y'.\n",
    "* Use only the tools mentioned below if and when needed.\n",
    "* The sub-tasks must not say 'store the data'. All the data is by default stored in memory.\n",
    "* Return the output in the form of an array, follow the below output format strictly.\n",
    "\n",
    "Tools:\n",
    "```\n",
    "$tools\n",
    "```\n",
    "\n",
    "Output format:\n",
    "```\n",
    "[\n",
    "    'sub-task 1', \n",
    "    'sub-task 2', \n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "Task: $input\n",
    "\n",
    "Return the output in the specified format, do not deviate. Do not add any text before or after the output.</s>\n",
    "<|assistant|>\"\"\")\n",
    "\n",
    "prompt = planner_template.substitute(input=\"Calculate the double of the age of Tom Cruise\", tools=get_current_tools())\n",
    "# print(prompt)\n",
    "set_current_plan(ollama_generate(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573ae06-8540-4eea-813e-31a7c57bc2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "thought_template = Template(\"\"\"<|system|>\n",
    "You are an assistant who is always helpful, harmless and honest.</s>\n",
    "<|user|>\n",
    "Your task is to extract the tool name and the input to the tool for the current step in the specified format.\n",
    "\n",
    "Instructions:\n",
    "* Do not say your knowledge is out of date, just return the requested information.\n",
    "* Do not say you are a AI language model.\n",
    "* Understand the `Current step` and extract the tool name and the complete input to the tool.\n",
    "* Refer to the list of tools available to get the right tool name.\n",
    "* Follow the below output format strictly.\n",
    "\n",
    "Current step: `$current_step`\n",
    "\n",
    "Tools:\n",
    "```\n",
    "$tools\n",
    "```\n",
    "\n",
    "Output format:\n",
    "```\n",
    "{\n",
    "    'current_step': \"current step that is being analyzed\",\n",
    "    'tool_name': \"name of the tool\",\n",
    "    'tool_input': [\"input 1\", \"input 2\", ...]\n",
    "}\n",
    "```\n",
    "\n",
    "Return the output in the specified format, do not deviate. Do not add any text before or after the output.</s>\n",
    "<|assistant|>\"\"\")\n",
    "\n",
    "prompt = action_template.substitute(current_step=get_current_step(), tools=get_current_tools())\n",
    "# print(prompt)\n",
    "print(ollama_generate(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f176820-fc4f-405f-85fe-2fdcd95741d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
